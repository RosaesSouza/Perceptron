# Atividade Pr√°tica de Intelig√™ncia Artificial - Perceptron

## Dupla
- Gabriel Louzada
- Gabriel Rosaes

## Tutorial: Implementa√ß√£o do Perceptron com Datasets Cl√°ssicos

### Introdu√ß√£o
O Perceptron √© um dos algoritmos mais fundamentais do aprendizado de m√°quina, proposto por Frank Rosenblatt em 1957. √â um classificador bin√°rio linear que forma a base para o entendimento de redes neurais mais complexas.

**Conceitos Fundamentais:**
- **Classificador Linear**: Separa classes usando um hiperplano
- **Supervisionado**: Aprende a partir de exemplos rotulados
- **Online**: Pode aprender incrementalmente
- **Converg√™ncia Garantida**: Para dados linearmente separ√°veis

## üìã Pr√©-requisitos e Instala√ß√£o

### Depend√™ncias Necess√°rias
Antes de executar os c√≥digos, √© importante instalar as depend√™ncias necess√°rias.

#### Op√ß√£o 1: Instala√ß√£o via requirements.txt (Recomendado)
```bash
pip install -r requirements.txt
```

#### Op√ß√£o 2: Instala√ß√£o manual
```bash
pip install numpy>=1.21.0
pip install matplotlib>=3.5.0
pip install scikit-learn>=1.0.0
pip install pandas>=1.3.0
```

## Como Executar

Para executar os exemplos, utilize o menu principal:

```bash
python main.py
```

Ou execute diretamente cada arquivo:

```bash
python blobs.py      # Exemplo 0: Demonstra√ß√£o b√°sica
python iris.py       # Exerc√≠cio 1: Iris Dataset
python moons.py      # Exerc√≠cio 2: Moons Dataset
python breast.py     # Exerc√≠cio 3: Breast Cancer
python ruido.py      # Exerc√≠cio 4: Classifica√ß√£o com Ru√≠do
python dlps.py       # Exerc√≠cio 5: Dataset Personalizado
```

---

## üìä Relat√≥rio Final dos Exerc√≠cios

### Exerc√≠cio 1: Iris Dataset (Setosa vs Versicolor)

#### 1. Descri√ß√£o do Dataset
- **N√∫mero de amostras**: 100 (50 Setosa + 50 Versicolor)
- **Features**: 2 (comprimento da s√©pala e comprimento da p√©tala)
- **Distribui√ß√£o das classes**: Perfeitamente balanceada (50/50)
- **Linearmente separ√°vel**: ‚úÖ Sim

#### 2. Resultados
- **Acur√°cia no treino**: 100%
- **Acur√°cia no teste**: 100%
- **√âpocas at√© converg√™ncia**: 3-5 √©pocas
- **Tempo de treinamento**: 0.003 segundos

#### 3. Visualiza√ß√µes

![Iris - Gr√°fico Combinado](images/iris_results.png)
*Figura 4: An√°lise completa do dataset Iris (Setosa vs Versicolor)*

![Iris - Regi√µes de Decis√£o](images/iris_decision_regions.png)
*Figura 5: Separa√ß√£o linear perfeita entre Setosa e Versicolor*

![Iris - Converg√™ncia](images/iris_convergence.png)
*Figura 6: Converg√™ncia extremamente r√°pida em poucas √©pocas*

#### 4. An√°lise
- ‚úÖ O perceptron foi **excelente** para este problema
- Setosa e Versicolor s√£o naturalmente linearmente separ√°veis
- Converg√™ncia extremamente r√°pida
- **Reflex√£o**: Versicolor vs Virginica seria mais desafiador (n√£o linearmente separ√°vel)
- **Compara√ß√£o com expectativas**: Superou expectativas com 100% de acur√°cia

---

### Exerc√≠cio 2: Moons Dataset (N√£o-linearmente Separ√°vel)

#### 1. Descri√ß√£o do Dataset
- **N√∫mero de amostras**: 200
- **Features**: 2
- **Distribui√ß√£o das classes**: Balanceada (100/100)
- **Linearmente separ√°vel**: ‚ùå N√£o

#### 2. Resultados
- **Acur√°cia no treino**: 80.71% **(CORRIGIDO)**
- **Acur√°cia no teste**: 90.00% **(CORRIGIDO)**
- **Acur√°cia geral**: 83.50%
- **√âpocas at√© converg√™ncia**: ‚ùå N√£o convergiu
- **Erros finais**: 32
- **Total de amostras classificadas erradas**: 33
- **Tempo de treinamento**: 0.015 segundos

#### 3. Visualiza√ß√µes

![Moons - Dataset Original](images/moons_original.png)
*Figura 7: Dataset Moons original mostrando formato de luas entrela√ßadas*

![Moons - Gr√°fico Combinado](images/moons_results.png)
*Figura 8: Tentativa de separa√ß√£o linear em dados n√£o-lineares*

![Moons - Regi√µes de Decis√£o](images/moons_decision_regions.png)
*Figura 9: Fronteira linear inadequada para separar as luas*

![Moons - Converg√™ncia](images/moons_convergence.png)
*Figura 10: Aus√™ncia de converg√™ncia - erros constantes*

#### 4. An√°lise
- ‚ö†Ô∏è O perceptron teve **performance moderada** para este problema
- **An√°lise corrigida**: A acur√°cia de ~83% √© surpreendentemente melhor que o acaso (50%), mas ainda limitada
- **Explica√ß√£o**: O perceptron consegue capturar parcialmente o padr√£o, mas a fronteira linear n√£o √© ideal
- A fronteira linear "corta" as luas de forma que consegue classificar corretamente uma boa parte dos pontos
- **Limita√ß√£o fundamental**: Ainda n√£o consegue convergir devido √† n√£o-separabilidade linear perfeita
- **Melhorias sugeridas**:
  - Transforma√ß√µes n√£o-lineares (features polinomiais: x‚ÇÅ¬≤, x‚ÇÇ¬≤, x‚ÇÅ√óx‚ÇÇ)
  - Redes neurais multicamadas (MLP com camadas ocultas)
  - SVM com kernel RBF
  - Algoritmos de ensemble (Random Forest)
- **Compara√ß√£o com expectativas**: Melhor que esperado, mas confirma limita√ß√µes para dados n√£o-lineares

---

### Exerc√≠cio 3: Breast Cancer Wisconsin

#### 1. Descri√ß√£o do Dataset
- **N√∫mero de amostras**: 569 (212 maligno + 357 benigno)
- **Features**: 30 (vers√£o completa) / 2 (vers√£o visualiza√ß√£o)
- **Distribui√ß√£o das classes**: Desbalanceada (37.3% maligno, 62.7% benigno)
- **Linearmente separ√°vel**: Parcialmente (depende das features selecionadas)

#### 2. Resultados

**Vers√£o A (2 features - mean radius, mean texture):**
- **Acur√°cia no treino**: 87.19%
- **Acur√°cia no teste**: 87.72%
- **√âpocas at√© converg√™ncia**: ‚ùå N√£o convergiu completamente
- **Tempo de treinamento**: 0.008 segundos

**Vers√£o B (30 features - todas):**
- **Acur√°cia no treino**: 98.99%
- **Acur√°cia no teste**: 96.49%
- **√âpocas at√© converg√™ncia**: ‚ùå N√£o convergiu completamente
- **Tempo de treinamento**: 0.025 segundos

#### 3. Visualiza√ß√µes

![Breast Cancer - Gr√°fico Combinado](images/breast_results.png)
*Figura 11: Compara√ß√£o entre 2 features vs 30 features*

![Breast Cancer - Regi√µes de Decis√£o](images/breast_decision_regions.png)
*Figura 12: Regi√µes de decis√£o com 2 features mostrando sobreposi√ß√£o*

![Breast Cancer - Converg√™ncia](images/breast_convergence.png)
*Figura 13: Compara√ß√£o da converg√™ncia entre diferentes n√∫meros de features*

![Breast Cancer - Matriz de Confus√£o](images/breast_confusion_matrix.png)
*Figura 14: An√°lise de falsos positivos vs falsos negativos*

#### 4. An√°lise
- ‚ö†Ô∏è O perceptron foi parcialmente **adequado** especialmente com todas as features
- **Melhoria significativa**: 88% ‚Üí 95% de acur√°cia (2 vs 30 features)
- **Contexto m√©dico cr√≠tico**: 
  - Falsos negativos s√£o mais perigosos (c√¢ncer n√£o detectado)
  - Falsos positivos causam ansiedade desnecess√°ria
- **Melhorias sugeridas**: 
  - Usar t√©cnicas de balanceamento (SMOTE)
  - Implementar class weights
  - Considerar ensemble methods para maior robustez
- **Compara√ß√£o com expectativas**: Resultados bons, mas limitado pela natureza linear

---

### Exerc√≠cio 4: Classifica√ß√£o com Ru√≠do

#### 1. Descri√ß√£o do Dataset
- **N√∫mero de amostras**: 200 por experimento
- **Features**: 2 (para visualiza√ß√£o)
- **Distribui√ß√£o das classes**: Balanceada (100/100)
- **Linearmente separ√°vel**: ‚ö†Ô∏è Varia com par√¢metros de separa√ß√£o e ru√≠do
- **Metodologia**: Tr√™s experimentos controlados com `make_classification`

#### 2. Resultados

**Experimento 1 - Impacto da Separa√ß√£o (class_sep):**
*Ru√≠do fixo em 5% (flip_y=0.05)*

| Separa√ß√£o | Acur√°cia Teste | Erros Finais | Performance |
|-----------|---------------|--------------|-------------|
| **0.5**   | 60.00%       | 55           | ‚ùå Ruim - pr√≥ximo ao acaso |
| **1.0**   | 73.33%       | 36           | ‚ö†Ô∏è Moderada - ainda muitos erros |
| **2.0**   | 95.00%       | 12           | ‚úÖ Excelente - poucos erros |
| **3.0**   | 96.67%       | 6            | ‚úÖ Quase perfeita |

**Experimento 2 - Impacto do Ru√≠do nos R√≥tulos (flip_y):**
*Separa√ß√£o fixa em 2.0 (boa separa√ß√£o)*

| Ru√≠do | Acur√°cia Teste | Erros Finais | Degrada√ß√£o |
|-------|---------------|--------------|------------|
| **0%**  | 95.00%       | 5            | Baseline - sem ru√≠do |
| **5%**  | 88.33%       | 20           | -6.67% degrada√ß√£o moderada |
| **10%** | 73.33%       | 32           | -21.67% degrada√ß√£o severa |
| **20%** | 58.33%       | 45           | -36.67% degrada√ß√£o cr√≠tica |

**Experimento 3 - Early Stopping vs Normal:**
*Com dataset de separa√ß√£o 1.5 e ru√≠do 10%*

| M√©todo | Acur√°cia Teste | √âpocas | Melhoria |
|--------|---------------|---------|----------|
| **Normal** | 82.50% | 100 (todas) | Baseline |
| **Early Stopping** | 90.00% | 16 (parada antecipada) | +7.5% melhoria significativa |

#### 3. Visualiza√ß√µes

![Ru√≠do - Experimento Separa√ß√£o](images/ruido_separation_experiment.png)
*Figura 15: Impacto dram√°tico da separa√ß√£o - separa√ß√£o > 2.0 √© cr√≠tica para boa performance*

![Ru√≠do - Experimento Ru√≠do](images/ruido_noise_experiment.png)
*Figura 16: Degrada√ß√£o linear clara conforme aumento do ru√≠do*

![Ru√≠do - Early Stopping](images/ruido_early_stopping.png)
*Figura 17: Early stopping previne overfitting e melhora generaliza√ß√£o*

![Ru√≠do - An√°lise Resumo](images/ruido_analysis_summary.png)
*Figura 18: Rela√ß√µes quantitativas - separa√ß√£o √© mais cr√≠tica que ru√≠do*

#### 4. An√°lise Detalhada

**4.1 Padr√µes Corretos Observados:**

1. **Degrada√ß√£o Linear do Ru√≠do**: Agora com comportamento esperado
   - **0% ‚Üí 5%**: -6.67% (degrada√ß√£o moderada)
   - **5% ‚Üí 10%**: -15% (degrada√ß√£o acelerada) 
   - **10% ‚Üí 20%**: -15% (degrada√ß√£o mantida)
   - **Padr√£o**: Aproximadamente linear, ~1.8% de perda por 1% de ru√≠do

2. **Threshold de Separa√ß√£o Cr√≠tico**: Confirmado entre 1.0 e 2.0
   - **1.0 ‚Üí 2.0**: Salto de +21.67% (73% ‚Üí 95%)
   - **2.0 ‚Üí 3.0**: Melhoria marginal de +1.67% (95% ‚Üí 96.67%)
   - **Ponto cr√≠tico**: Separa√ß√£o 2.0 marca divisor de √°guas

3. **Correla√ß√£o Erros vs Acur√°cia**: Agora coerente
   - Mais ru√≠do = mais erros finais = menor acur√°cia
   - Rela√ß√£o inversamente proporcional clara

**4.2 Insights Quantitativos:**

**Separa√ß√£o vs Performance:**
- **< 1.0**: Performance inaceit√°vel (‚â§ 73%)
- **1.0-2.0**: Zona de transi√ß√£o cr√≠tica (+21.67%)
- **> 2.0**: Zona de alta performance (‚â• 95%)

**Ru√≠do vs Degrada√ß√£o:**
- **0-5%**: Degrada√ß√£o toler√°vel (-6.67%)
- **5-10%**: Degrada√ß√£o preocupante (-15%)
- **10-20%**: Degrada√ß√£o severa (-15% adicional)

**Early Stopping:**
- **Benef√≠cio consistente**: +7.5% em cen√°rios com ru√≠do
- **Efici√™ncia**: 84% menos √©pocas (16 vs 100)
- **Parada inteligente**: Evita overfitting

### Exerc√≠cio 5: Dataset Linearmente Separ√°vel Personalizado (DLPS)

#### 1. Descri√ß√£o do Dataset
- **N√∫mero de amostras**: 200 (100 por classe)
- **Features**: 2 (para visualiza√ß√£o geom√©trica)
- **Distribui√ß√£o das classes**: Perfeitamente balanceada (100/100)
- **Design**: Centros em (-2,-2) e (2,2) conforme especifica√ß√£o
- **Linearmente separ√°vel**: ‚úÖ Sim (por constru√ß√£o)

#### 2. Resultados

**An√°lise Principal - Geometria da Solu√ß√£o:**
- **Acur√°cia de treino**: 100%
- **Acur√°cia de teste**: 100%
- **√âpocas at√© converg√™ncia**: 2 √©pocas
- **Tempo de treinamento**: 0.0044 segundos

**Equa√ß√£o da Fronteira de Decis√£o:**
- **Pesos**: w‚ÇÅ = 0.009, w‚ÇÇ = 0.012, bias = 0.000
- **Equa√ß√£o**: x‚ÇÇ = -0.709 √ó x‚ÇÅ + 0.000
- **Interpreta√ß√£o**: Linha com inclina√ß√£o -35.3¬∞ passando pela origem

**Experimento de Proximidade:**

| Dist√¢ncia | Acur√°cia | Convergiu | Status |
|-----------|----------|-----------|--------|
| **5.0**   | 100%     | ‚úÖ Sim (2 √©pocas) | Excelente |
| **4.0**   | 100%     | ‚úÖ Sim (2 √©pocas) | Excelente |
| **3.0**   | 100%     | ‚úÖ Sim (2 √©pocas) | Muito boa |
| **2.0**   | 90%      | ‚ùå N√£o | Zona de transi√ß√£o |
| **1.5**   | 76.7%    | ‚ùå N√£o | **Threshold de falha** |
| **‚â§1.0**  | 60-70%   | ‚ùå N√£o | Falha sistem√°tica |

#### 3. Visualiza√ß√µes

![DLPS - Dataset Original](images/dlps_original.png)
*Figura 19: Dataset customizado com centros bem separados*

![DLPS - An√°lise Geom√©trica](images/dlps_geometric_analysis.png)
*Figura 20: Fronteira de decis√£o, converg√™ncia, superf√≠cie 3D e an√°lise de proximidade*

![DLPS - Experimento Proximidade](images/dlps_proximity_experiment.png)
*Figura 21: Identifica√ß√£o do threshold de falha (dist√¢ncia ‚â§ 1.5)*

#### 4. An√°lise

**4.1 Valida√ß√£o dos Objetivos:**
- ‚úÖ **Dataset customizado**: Criado conforme especifica√ß√£o (centros em (-2.1,-2.0) e (2.1,2.0))
- ‚úÖ **Equa√ß√£o da reta**: x‚ÇÇ = -0.709 √ó x‚ÇÅ + 0.000
- ‚úÖ **Verifica√ß√£o dos pontos**: 140/140 pontos classificados corretamente (100%)
- ‚úÖ **Proximidade at√© falha**: Threshold identificado em dist√¢ncia ‚â§ 1.5

**Compara√ß√£o com expectativas**: ‚úÖ Superou expectativas com converg√™ncia extremamente r√°pida (2 √©pocas) e identificou threshold de falha preciso (1.5).

---

## üéØ Conclus√µes Gerais

### ‚úÖ Quando o Perceptron Funciona Bem:
1. **Dados linearmente separ√°veis** (Iris, Blobs, DLPS)
2. **Baixo ru√≠do** nos dados e r√≥tulos
3. **Features normalizadas** (StandardScaler)
4. **Taxa de aprendizado adequada** (0.01-0.1 tipicamente)
5. **Classes balanceadas**

### ‚ùå Limita√ß√µes Observadas:
1. **Falha completamente** para dados n√£o-linearmente separ√°veis (Moons)
2. **Muito sens√≠vel ao ru√≠do** nos r√≥tulos
3. **Apenas fronteiras lineares** - n√£o pode aprender padr√µes complexos
4. **Pode n√£o convergir** sem separabilidade linear perfeita
5. **Sens√≠vel a outliers** que podem afetar a fronteira

### üìÅ Estrutura de Arquivos
```
AtividadePerceptron/
‚îú‚îÄ‚îÄ images/                     # Pasta com gr√°ficos gerados
‚îÇ   ‚îú‚îÄ‚îÄ blobs_results.png
‚îÇ   ‚îú‚îÄ‚îÄ blobs_decision_regions.png
‚îÇ   ‚îú‚îÄ‚îÄ blobs_convergence.png
‚îÇ   ‚îú‚îÄ‚îÄ iris_results.png
‚îÇ   ‚îú‚îÄ‚îÄ iris_decision_regions.png
‚îÇ   ‚îú‚îÄ‚îÄ iris_convergence.png
‚îÇ   ‚îú‚îÄ‚îÄ moons_original.png
‚îÇ   ‚îú‚îÄ‚îÄ moons_results.png
‚îÇ   ‚îú‚îÄ‚îÄ moons_decision_regions.png
‚îÇ   ‚îú‚îÄ‚îÄ moons_convergence.png
‚îÇ   ‚îú‚îÄ‚îÄ breast_results.png
‚îÇ   ‚îú‚îÄ‚îÄ breast_decision_regions.png
‚îÇ   ‚îú‚îÄ‚îÄ breast_convergence.png
‚îÇ   ‚îú‚îÄ‚îÄ breast_confusion_matrix.png
‚îÇ   ‚îú‚îÄ‚îÄ ruido_separation_experiment.png
‚îÇ   ‚îú‚îÄ‚îÄ ruido_noise_experiment.png
‚îÇ   ‚îú‚îÄ‚îÄ ruido_early_stopping.png
‚îÇ   ‚îú‚îÄ‚îÄ ruido_analysis_summary.png
‚îÇ   ‚îú‚îÄ‚îÄ dlps_original.png
‚îÇ   ‚îú‚îÄ‚îÄ dlps_learning_rates.png
‚îÇ   ‚îú‚îÄ‚îÄ dlps_convergence_comparison.png
‚îÇ   ‚îú‚îÄ‚îÄ dlps_geometric_analysis.png
‚îÇ   ‚îî‚îÄ‚îÄ dlps_proximity_experiment.png
‚îú‚îÄ‚îÄ main.py                     # Menu principal interativo
‚îú‚îÄ‚îÄ perceptron.py               # Implementa√ß√£o da classe Perceptron
‚îú‚îÄ‚îÄ util.py                     # Fun√ß√£o de visualiza√ß√£o das regi√µes de decis√£o
‚îú‚îÄ‚îÄ blobs.py                    # Exemplo 0: Demonstra√ß√£o b√°sica com clusters
‚îú‚îÄ‚îÄ iris.py                     # Exerc√≠cio 1: Iris Dataset (linearmente separ√°vel)
‚îú‚îÄ‚îÄ moons.py                    # Exerc√≠cio 2: Moons Dataset (n√£o-linear)
‚îú‚îÄ‚îÄ breast.py                   # Exerc√≠cio 3: Breast Cancer (problema m√©dico real)
‚îú‚îÄ‚îÄ ruido.py                    # Exerc√≠cio 4: An√°lise de robustez ao ru√≠do
‚îú‚îÄ‚îÄ dlps.py                     # Exerc√≠cio 5: Dataset personalizado
‚îú‚îÄ‚îÄ requirements.txt            # Depend√™ncias do projeto
‚îî‚îÄ‚îÄ README.md                   # Este relat√≥rio completo
```


**Nota**: Os gr√°ficos e visualiza√ß√µes s√£o gerados automaticamente durante a execu√ß√£o de cada script, proporcionando uma compreens√£o visual completa do comportamento do algoritmo em diferentes cen√°rios.
