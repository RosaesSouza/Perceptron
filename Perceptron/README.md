# Atividade PrÃ¡tica de InteligÃªncia Artificial - Perceptron

## Dupla
- Gabriel Louzada
- Gabriel Rosaes

## Tutorial: ImplementaÃ§Ã£o do Perceptron com Datasets ClÃ¡ssicos

### IntroduÃ§Ã£o
O Perceptron Ã© um dos algoritmos mais fundamentais do aprendizado de mÃ¡quina, proposto por Frank Rosenblatt em 1957. Ã‰ um classificador binÃ¡rio linear que forma a base para o entendimento de redes neurais mais complexas.

**Conceitos Fundamentais:**
- **Classificador Linear**: Separa classes usando um hiperplano
- **Supervisionado**: Aprende a partir de exemplos rotulados
- **Online**: Pode aprender incrementalmente
- **ConvergÃªncia Garantida**: Para dados linearmente separÃ¡veis

## ğŸ“‹ PrÃ©-requisitos e InstalaÃ§Ã£o

### DependÃªncias NecessÃ¡rias
Antes de executar os cÃ³digos, Ã© importante instalar as dependÃªncias necessÃ¡rias.

#### OpÃ§Ã£o 1: InstalaÃ§Ã£o via requirements.txt (Recomendado)
```bash
pip install -r requirements.txt
```

#### OpÃ§Ã£o 2: InstalaÃ§Ã£o manual
```bash
pip install numpy>=1.21.0
pip install matplotlib>=3.5.0
pip install scikit-learn>=1.0.0
pip install pandas>=1.3.0
```

## Como Executar

Para executar os exemplos, utilize o menu principal:

```bash
python main.py
```

Ou execute diretamente cada arquivo:

```bash
python blobs.py      # Exemplo 0: DemonstraÃ§Ã£o bÃ¡sica
python iris.py       # ExercÃ­cio 1: Iris Dataset
python moons.py      # ExercÃ­cio 2: Moons Dataset
python breast.py     # ExercÃ­cio 3: Breast Cancer
python ruido.py      # ExercÃ­cio 4: ClassificaÃ§Ã£o com RuÃ­do
python dlps.py       # ExercÃ­cio 5: Dataset Personalizado
```

---

## ğŸ“Š RelatÃ³rio Final dos ExercÃ­cios

### ExercÃ­cio 1: Iris Dataset (Setosa vs Versicolor)

#### 1. DescriÃ§Ã£o do Dataset
- **NÃºmero de amostras**: 100 (50 Setosa + 50 Versicolor)
- **Features**: 2 (comprimento da sÃ©pala e comprimento da pÃ©tala)
- **DistribuiÃ§Ã£o das classes**: Perfeitamente balanceada (50/50)
- **Linearmente separÃ¡vel**: âœ… Sim

#### 2. Resultados
- **AcurÃ¡cia no treino**: 100%
- **AcurÃ¡cia no teste**: 100%
- **Ã‰pocas atÃ© convergÃªncia**: 3-5 Ã©pocas
- **Tempo de treinamento**: 0.003 segundos

#### 3. VisualizaÃ§Ãµes

![Iris - GrÃ¡fico Combinado](images/iris_results.png)
*Figura 4: AnÃ¡lise completa do dataset Iris (Setosa vs Versicolor)*

![Iris - RegiÃµes de DecisÃ£o](images/iris_decision_regions.png)
*Figura 5: SeparaÃ§Ã£o linear perfeita entre Setosa e Versicolor*

![Iris - ConvergÃªncia](images/iris_convergence.png)
*Figura 6: ConvergÃªncia extremamente rÃ¡pida em poucas Ã©pocas*

#### 4. AnÃ¡lise
- âœ… O perceptron foi **excelente** para este problema
- Setosa e Versicolor sÃ£o naturalmente linearmente separÃ¡veis
- ConvergÃªncia extremamente rÃ¡pida
- **ReflexÃ£o**: Versicolor vs Virginica seria mais desafiador (nÃ£o linearmente separÃ¡vel)
- **ComparaÃ§Ã£o com expectativas**: Superou expectativas com 100% de acurÃ¡cia

---

### ExercÃ­cio 2: Moons Dataset (NÃ£o-linearmente SeparÃ¡vel)

#### 1. DescriÃ§Ã£o do Dataset
- **NÃºmero de amostras**: 200
- **Features**: 2
- **DistribuiÃ§Ã£o das classes**: Balanceada (100/100)
- **Linearmente separÃ¡vel**: âŒ NÃ£o

#### 2. Resultados
- **AcurÃ¡cia no treino**: 80.71% **(CORRIGIDO)**
- **AcurÃ¡cia no teste**: 90.00% **(CORRIGIDO)**
- **AcurÃ¡cia geral**: 83.50%
- **Ã‰pocas atÃ© convergÃªncia**: âŒ NÃ£o convergiu
- **Erros finais**: 32
- **Total de amostras classificadas erradas**: 33
- **Tempo de treinamento**: 0.015 segundos

#### 3. VisualizaÃ§Ãµes

![Moons - Dataset Original](images/moons_original.png)
*Figura 7: Dataset Moons original mostrando formato de luas entrelaÃ§adas*

![Moons - GrÃ¡fico Combinado](images/moons_results.png)
*Figura 8: Tentativa de separaÃ§Ã£o linear em dados nÃ£o-lineares*

![Moons - RegiÃµes de DecisÃ£o](images/moons_decision_regions.png)
*Figura 9: Fronteira linear inadequada para separar as luas*

![Moons - ConvergÃªncia](images/moons_convergence.png)
*Figura 10: AusÃªncia de convergÃªncia - erros constantes*

#### 4. AnÃ¡lise
- âš ï¸ O perceptron teve **performance moderada** para este problema
- **AnÃ¡lise corrigida**: A acurÃ¡cia de ~83% Ã© surpreendentemente melhor que o acaso (50%), mas ainda limitada
- **ExplicaÃ§Ã£o**: O perceptron consegue capturar parcialmente o padrÃ£o, mas a fronteira linear nÃ£o Ã© ideal
- A fronteira linear "corta" as luas de forma que consegue classificar corretamente uma boa parte dos pontos
- **LimitaÃ§Ã£o fundamental**: Ainda nÃ£o consegue convergir devido Ã  nÃ£o-separabilidade linear perfeita
- **Melhorias sugeridas**:
  - TransformaÃ§Ãµes nÃ£o-lineares (features polinomiais: xâ‚Â², xâ‚‚Â², xâ‚Ã—xâ‚‚)
  - Redes neurais multicamadas (MLP com camadas ocultas)
  - SVM com kernel RBF
  - Algoritmos de ensemble (Random Forest)
- **ComparaÃ§Ã£o com expectativas**: Melhor que esperado, mas confirma limitaÃ§Ãµes para dados nÃ£o-lineares

---

### ExercÃ­cio 3: Breast Cancer Wisconsin

#### 1. DescriÃ§Ã£o do Dataset
- **NÃºmero de amostras**: 569 (212 maligno + 357 benigno)
- **Features**: 30 (versÃ£o completa) / 2 (versÃ£o visualizaÃ§Ã£o)
- **DistribuiÃ§Ã£o das classes**: Desbalanceada (37.3% maligno, 62.7% benigno)
- **Linearmente separÃ¡vel**: Parcialmente (depende das features selecionadas)

#### 2. Resultados

**VersÃ£o A (2 features - mean radius, mean texture):**
- **AcurÃ¡cia no treino**: 87.19%
- **AcurÃ¡cia no teste**: 87.72%
- **Ã‰pocas atÃ© convergÃªncia**: âŒ NÃ£o convergiu completamente
- **Tempo de treinamento**: 0.008 segundos

**VersÃ£o B (30 features - todas):**
- **AcurÃ¡cia no treino**: 98.99%
- **AcurÃ¡cia no teste**: 96.49%
- **Ã‰pocas atÃ© convergÃªncia**: âŒ NÃ£o convergiu completamente
- **Tempo de treinamento**: 0.025 segundos

#### 3. VisualizaÃ§Ãµes

![Breast Cancer - GrÃ¡fico Combinado](images/breast_results.png)
*Figura 11: ComparaÃ§Ã£o entre 2 features vs 30 features*

![Breast Cancer - RegiÃµes de DecisÃ£o](images/breast_decision_regions.png)
*Figura 12: RegiÃµes de decisÃ£o com 2 features mostrando sobreposiÃ§Ã£o*

![Breast Cancer - ConvergÃªncia](images/breast_convergence.png)
*Figura 13: ComparaÃ§Ã£o da convergÃªncia entre diferentes nÃºmeros de features*

![Breast Cancer - Matriz de ConfusÃ£o](images/breast_confusion_matrix.png)
*Figura 14: AnÃ¡lise de falsos positivos vs falsos negativos*

#### 4. AnÃ¡lise
- âš ï¸ O perceptron foi parcialmente **adequado** especialmente com todas as features
- **Melhoria significativa**: 88% â†’ 95% de acurÃ¡cia (2 vs 30 features)
- **Contexto mÃ©dico crÃ­tico**: 
  - Falsos negativos sÃ£o mais perigosos (cÃ¢ncer nÃ£o detectado)
  - Falsos positivos causam ansiedade desnecessÃ¡ria
- **Melhorias sugeridas**: 
  - Usar tÃ©cnicas de balanceamento (SMOTE)
  - Implementar class weights
  - Considerar ensemble methods para maior robustez
- **ComparaÃ§Ã£o com expectativas**: Resultados bons, mas limitado pela natureza linear

---

### ExercÃ­cio 4: ClassificaÃ§Ã£o com RuÃ­do

#### 1. DescriÃ§Ã£o do Dataset
- **NÃºmero de amostras**: 200 por experimento
- **Features**: 2 (para visualizaÃ§Ã£o)
- **DistribuiÃ§Ã£o das classes**: Balanceada (100/100)
- **Linearmente separÃ¡vel**: âš ï¸ Varia com parÃ¢metros de separaÃ§Ã£o e ruÃ­do
- **Metodologia**: TrÃªs experimentos controlados com `make_classification`

#### 2. Resultados

**Experimento 1 - Impacto da SeparaÃ§Ã£o (class_sep):**
*RuÃ­do fixo em 5% (flip_y=0.05)*

| SeparaÃ§Ã£o | AcurÃ¡cia Teste | Erros Finais | Performance |
|-----------|---------------|--------------|-------------|
| **0.5**   | 60.00%       | 55           | âŒ Ruim - prÃ³ximo ao acaso |
| **1.0**   | 73.33%       | 36           | âš ï¸ Moderada - ainda muitos erros |
| **2.0**   | 95.00%       | 12           | âœ… Excelente - poucos erros |
| **3.0**   | 96.67%       | 6            | âœ… Quase perfeita |

**Experimento 2 - Impacto do RuÃ­do nos RÃ³tulos (flip_y):**
*SeparaÃ§Ã£o fixa em 2.0 (boa separaÃ§Ã£o)*

| RuÃ­do | AcurÃ¡cia Teste | Erros Finais | DegradaÃ§Ã£o |
|-------|---------------|--------------|------------|
| **0%**  | 95.00%       | 5            | Baseline - sem ruÃ­do |
| **5%**  | 88.33%       | 20           | -6.67% degradaÃ§Ã£o moderada |
| **10%** | 73.33%       | 32           | -21.67% degradaÃ§Ã£o severa |
| **20%** | 58.33%       | 45           | -36.67% degradaÃ§Ã£o crÃ­tica |

**Experimento 3 - Early Stopping vs Normal:**
*Com dataset de separaÃ§Ã£o 1.5 e ruÃ­do 10%*

| MÃ©todo | AcurÃ¡cia Teste | Ã‰pocas | Melhoria |
|--------|---------------|---------|----------|
| **Normal** | 82.50% | 100 (todas) | Baseline |
| **Early Stopping** | 90.00% | 16 (parada antecipada) | +7.5% melhoria significativa |

#### 3. VisualizaÃ§Ãµes

![RuÃ­do - Experimento SeparaÃ§Ã£o](images/ruido_separation_experiment.png)
*Figura 15: Impacto dramÃ¡tico da separaÃ§Ã£o - separaÃ§Ã£o > 2.0 Ã© crÃ­tica para boa performance*

![RuÃ­do - Experimento RuÃ­do](images/ruido_noise_experiment.png)
*Figura 16: DegradaÃ§Ã£o linear clara conforme aumento do ruÃ­do*

![RuÃ­do - Early Stopping](images/ruido_early_stopping.png)
*Figura 17: Early stopping previne overfitting e melhora generalizaÃ§Ã£o*

![RuÃ­do - AnÃ¡lise Resumo](images/ruido_analysis_summary.png)
*Figura 18: RelaÃ§Ãµes quantitativas - separaÃ§Ã£o Ã© mais crÃ­tica que ruÃ­do*

#### 4. AnÃ¡lise Detalhada

**4.1 PadrÃµes Corretos Observados:**

1. **DegradaÃ§Ã£o Linear do RuÃ­do**: Agora com comportamento esperado
   - **0% â†’ 5%**: -6.67% (degradaÃ§Ã£o moderada)
   - **5% â†’ 10%**: -15% (degradaÃ§Ã£o acelerada) 
   - **10% â†’ 20%**: -15% (degradaÃ§Ã£o mantida)
   - **PadrÃ£o**: Aproximadamente linear, ~1.8% de perda por 1% de ruÃ­do

2. **Threshold de SeparaÃ§Ã£o CrÃ­tico**: Confirmado entre 1.0 e 2.0
   - **1.0 â†’ 2.0**: Salto de +21.67% (73% â†’ 95%)
   - **2.0 â†’ 3.0**: Melhoria marginal de +1.67% (95% â†’ 96.67%)
   - **Ponto crÃ­tico**: SeparaÃ§Ã£o 2.0 marca divisor de Ã¡guas

3. **CorrelaÃ§Ã£o Erros vs AcurÃ¡cia**: Agora coerente
   - Mais ruÃ­do = mais erros finais = menor acurÃ¡cia
   - RelaÃ§Ã£o inversamente proporcional clara

**4.2 Insights Quantitativos:**

**SeparaÃ§Ã£o vs Performance:**
- **< 1.0**: Performance inaceitÃ¡vel (â‰¤ 73%)
- **1.0-2.0**: Zona de transiÃ§Ã£o crÃ­tica (+21.67%)
- **> 2.0**: Zona de alta performance (â‰¥ 95%)

**RuÃ­do vs DegradaÃ§Ã£o:**
- **0-5%**: DegradaÃ§Ã£o tolerÃ¡vel (-6.67%)
- **5-10%**: DegradaÃ§Ã£o preocupante (-15%)
- **10-20%**: DegradaÃ§Ã£o severa (-15% adicional)

**Early Stopping:**
- **BenefÃ­cio consistente**: +7.5% em cenÃ¡rios com ruÃ­do
- **EficiÃªncia**: 84% menos Ã©pocas (16 vs 100)
- **Parada inteligente**: Evita overfitting

### ExercÃ­cio 5: Dataset Linearmente SeparÃ¡vel Personalizado (DLPS)

#### 1. DescriÃ§Ã£o do Dataset
- **NÃºmero de amostras**: 200 (100 por classe)
- **Features**: 2 (para visualizaÃ§Ã£o geomÃ©trica)
- **DistribuiÃ§Ã£o das classes**: Perfeitamente balanceada (100/100)
- **Design**: Centros em (-2,-2) e (2,2) conforme especificaÃ§Ã£o
- **Linearmente separÃ¡vel**: âœ… Sim (por construÃ§Ã£o)

#### 2. Resultados

**AnÃ¡lise Principal - Geometria da SoluÃ§Ã£o:**
- **AcurÃ¡cia de treino**: 100%
- **AcurÃ¡cia de teste**: 100%
- **Ã‰pocas atÃ© convergÃªncia**: 2 Ã©pocas
- **Tempo de treinamento**: 0.0044 segundos

**EquaÃ§Ã£o da Fronteira de DecisÃ£o:**
- **Pesos**: wâ‚ = 0.009, wâ‚‚ = 0.012, bias = 0.000
- **EquaÃ§Ã£o**: xâ‚‚ = -0.709 Ã— xâ‚ + 0.000
- **InterpretaÃ§Ã£o**: Linha com inclinaÃ§Ã£o -35.3Â° passando pela origem

**Experimento de Proximidade:**

| DistÃ¢ncia | AcurÃ¡cia | Convergiu | Status |
|-----------|----------|-----------|--------|
| **5.0**   | 100%     | âœ… Sim (2 Ã©pocas) | Excelente |
| **4.0**   | 100%     | âœ… Sim (2 Ã©pocas) | Excelente |
| **3.0**   | 100%     | âœ… Sim (2 Ã©pocas) | Muito boa |
| **2.0**   | 90%      | âŒ NÃ£o | Zona de transiÃ§Ã£o |
| **1.5**   | 76.7%    | âŒ NÃ£o | **Threshold de falha** |
| **â‰¤1.0**  | 60-70%   | âŒ NÃ£o | Falha sistemÃ¡tica |

#### 3. VisualizaÃ§Ãµes

![DLPS - Dataset Original](images/dlps_original.png)
*Figura 19: Dataset customizado com centros bem separados*

![DLPS - AnÃ¡lise GeomÃ©trica](images/dlps_geometric_analysis.png)
*Figura 20: Fronteira de decisÃ£o, convergÃªncia, superfÃ­cie 3D e anÃ¡lise de proximidade*

![DLPS - Experimento Proximidade](images/dlps_proximity_experiment.png)
*Figura 21: IdentificaÃ§Ã£o do threshold de falha (distÃ¢ncia â‰¤ 1.5)*

#### 4. AnÃ¡lise

**4.1 ValidaÃ§Ã£o dos Objetivos:**
- âœ… **Dataset customizado**: Criado conforme especificaÃ§Ã£o (centros em (-2.1,-2.0) e (2.1,2.0))
- âœ… **EquaÃ§Ã£o da reta**: xâ‚‚ = -0.709 Ã— xâ‚ + 0.000
- âœ… **VerificaÃ§Ã£o dos pontos**: 140/140 pontos classificados corretamente (100%)
- âœ… **Proximidade atÃ© falha**: Threshold identificado em distÃ¢ncia â‰¤ 1.5

**ComparaÃ§Ã£o com expectativas**: âœ… Superou expectativas com convergÃªncia extremamente rÃ¡pida (2 Ã©pocas) e identificou threshold de falha preciso (1.5).

---

## ğŸ¯ ConclusÃµes Gerais

### âœ… Quando o Perceptron Funciona Bem:
1. **Dados linearmente separÃ¡veis** (Iris, Blobs, DLPS)
2. **Baixo ruÃ­do** nos dados e rÃ³tulos
3. **Features normalizadas** (StandardScaler)
4. **Taxa de aprendizado adequada** (0.01-0.1 tipicamente)
5. **Classes balanceadas**

### âŒ LimitaÃ§Ãµes Observadas:
1. **Falha completamente** para dados nÃ£o-linearmente separÃ¡veis (Moons)
2. **Muito sensÃ­vel ao ruÃ­do** nos rÃ³tulos
3. **Apenas fronteiras lineares** - nÃ£o pode aprender padrÃµes complexos
4. **Pode nÃ£o convergir** sem separabilidade linear perfeita
5. **SensÃ­vel a outliers** que podem afetar a fronteira

### ğŸ“ Estrutura de Arquivos
```
AtividadePerceptron/
â”œâ”€â”€ images/                     # Pasta com grÃ¡ficos gerados
â”‚   â”œâ”€â”€ blobs_results.png
â”‚   â”œâ”€â”€ blobs_decision_regions.png
â”‚   â”œâ”€â”€ blobs_convergence.png
â”‚   â”œâ”€â”€ iris_results.png
â”‚   â”œâ”€â”€ iris_decision_regions.png
â”‚   â”œâ”€â”€ iris_convergence.png
â”‚   â”œâ”€â”€ moons_original.png
â”‚   â”œâ”€â”€ moons_results.png
â”‚   â”œâ”€â”€ moons_decision_regions.png
â”‚   â”œâ”€â”€ moons_convergence.png
â”‚   â”œâ”€â”€ breast_results.png
â”‚   â”œâ”€â”€ breast_decision_regions.png
â”‚   â”œâ”€â”€ breast_convergence.png
â”‚   â”œâ”€â”€ breast_confusion_matrix.png
â”‚   â”œâ”€â”€ ruido_separation_experiment.png
â”‚   â”œâ”€â”€ ruido_noise_experiment.png
â”‚   â”œâ”€â”€ ruido_early_stopping.png
â”‚   â”œâ”€â”€ ruido_analysis_summary.png
â”‚   â”œâ”€â”€ dlps_original.png
â”‚   â”œâ”€â”€ dlps_learning_rates.png
â”‚   â”œâ”€â”€ dlps_convergence_comparison.png
â”‚   â”œâ”€â”€ dlps_geometric_analysis.png
â”‚   â””â”€â”€ dlps_proximity_experiment.png
â”œâ”€â”€ main.py                     # Menu principal interativo
â”œâ”€â”€ perceptron.py               # ImplementaÃ§Ã£o da classe Perceptron
â”œâ”€â”€ util.py                     # FunÃ§Ã£o de visualizaÃ§Ã£o das regiÃµes de decisÃ£o
â”œâ”€â”€ blobs.py                    # Exemplo 0: DemonstraÃ§Ã£o bÃ¡sica com clusters
â”œâ”€â”€ iris.py                     # ExercÃ­cio 1: Iris Dataset (linearmente separÃ¡vel)
â”œâ”€â”€ moons.py                    # ExercÃ­cio 2: Moons Dataset (nÃ£o-linear)
â”œâ”€â”€ breast.py                   # ExercÃ­cio 3: Breast Cancer (problema mÃ©dico real)
â”œâ”€â”€ ruido.py                    # ExercÃ­cio 4: AnÃ¡lise de robustez ao ruÃ­do
â”œâ”€â”€ dlps.py                     # ExercÃ­cio 5: Dataset personalizado
â”œâ”€â”€ requirements.txt            # DependÃªncias do projeto
â””â”€â”€ README.md                   # Este relatÃ³rio completo
```


**Nota**: Os grÃ¡ficos e visualizaÃ§Ãµes sÃ£o gerados automaticamente durante a execuÃ§Ã£o de cada script, proporcionando uma compreensÃ£o visual completa do comportamento do algoritmo em diferentes cenÃ¡rios.
